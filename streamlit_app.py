import re
import requests
import streamlit as st
from bs4 import BeautifulSoup
from urllib.parse import urljoin

st.set_page_config(page_title="Page Mirror", layout="wide")

UA = {"user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                    "(KHTML, like Gecko) Chrome/126.0 Safari/537.36"}

@st.cache_data(show_spinner=False, ttl=600)
def fetch_url(url: str):
    r = requests.get(url, headers=UA, timeout=20)
    r.raise_for_status()
    return r.text, r.url  # content + final URL after redirects

def absolutize_links(soup: BeautifulSoup, base_url: str):
    # Ø­Ø· <base> Ø¹Ø´Ø§Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù†Ø³Ø¨ÙŠØ© ØªØªØµØ±Ù ØµØ­
    if not soup.head:
        soup.insert(0, soup.new_tag("head"))
    # Ø§Ø­Ø°Ù Ø£ÙŠ base Ù‚Ø¯ÙŠÙ…
    for b in soup.find_all("base"):
        b.decompose()
    base = soup.new_tag("base", href=base_url)
    soup.head.insert(0, base)

def drop_csp_and_noscript(soup: BeautifulSoup):
    # Ø§Ù…Ø³Ø­ Ù‚ÙŠÙˆØ¯ Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ù„ÙŠ ØªÙ…Ù†Ø¹ ØªØ´ØºÙŠÙ„ Ø³ÙƒØ±Ø¨Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…ÙƒÙˆÙ‘Ù†
    for m in soup.find_all("meta", attrs={"http-equiv": re.compile("content-security-policy", re.I)}):
        m.decompose()
    # ØµÙØ­Ø§Øª ÙƒØªÙŠØ± ØªØ³ØªØ®Ø¯Ù… noscript ÙŠØ¨ÙˆÙ‘Ø² Ø§Ù„Ø´ÙƒÙ„ Ø¯Ø§Ø®Ù„ iframe/inline
    for ns in soup.find_all("noscript"):
        ns.decompose()

def inline_css_js(soup: BeautifulSoup, base_url: str, max_bytes: int = 400_000):
    """Ù†Ø­Ø§ÙˆÙ„ Ù†Ø¶Ù…Ù‘Ù† CSS/JS Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ (Ù„Ùˆ Ø­Ø¬Ù…Ù‡ Ù…Ø¹Ù‚ÙˆÙ„)."""
    # CSS
    for link in list(soup.find_all("link", rel=lambda v: v and "stylesheet" in v)):
        href = link.get("href")
        if not href:
            continue
        absurl = urljoin(base_url, href)
        try:
            css = requests.get(absurl, headers=UA, timeout=15).content
            if len(css) <= max_bytes:
                style = soup.new_tag("style")
                style.string = css.decode("utf-8", errors="ignore")
                link.replace_with(style)
            else:
                # Ø®Ù„Ù‘ÙŠÙ‡Ø§ Ù…Ø·Ù„Ù‚Ø© Ø¨Ø¯Ù„ Ù†Ø³Ø¨ÙŠØ©
                link["href"] = absurl
        except Exception:
            # ÙØ´Ù„ØŸ Ø®Ù„Ù‘ÙŠÙ‡Ø§ Ù…Ø·Ù„Ù‚Ø©
            link["href"] = absurl

    # JS
    for s in list(soup.find_all("script", src=True)):
        src = s.get("src")
        absurl = urljoin(base_url, src)
        try:
            js = requests.get(absurl, headers=UA, timeout=15).content
            if len(js) <= max_bytes:
                new = soup.new_tag("script")
                new.string = js.decode("utf-8", errors="ignore")
                s.replace_with(new)
            else:
                s["src"] = absurl
                # Ø¥Ø²Ø§Ù„Ø© SRI Ù‚Ø¯ ØªÙ…Ù†Ø¹ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¹Ø¨Ø± origin Ù…Ø®ØªÙ„Ù
                s.attrs.pop("integrity", None)
                s.attrs.pop("crossorigin", None)
        except Exception:
            s["src"] = absurl
            s.attrs.pop("integrity", None)
            s.attrs.pop("crossorigin", None)

def unsandbox_iframes(soup: BeautifulSoup):
    # Ù„Ùˆ ÙÙŠ iframes Ø¯Ø§Ø®Ù„ Ø§Ù„ØµÙØ­Ø©ØŒ Ø´ÙŠÙ„ sandbox Ù„ØªØ´ØªØºÙ„ Ù…Ø­Ù„ÙŠÙ‹Ø§
    for fr in soup.find_all("iframe"):
        if fr.has_attr("sandbox"):
            del fr["sandbox"]

def flatten(url: str) -> str:
    """Ø§Ø±Ø¬Ø¹ HTML Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø¹Ø±Ø¶ Ø¯Ø§Ø®Ù„ Streamlit components.html."""
    html, final_url = fetch_url(url)
    soup = BeautifulSoup(html, "lxml")

    # ØªÙ‡ÙŠØ¦Ø©
    drop_csp_and_noscript(soup)
    absolutize_links(soup, final_url)
    inline_css_js(soup, final_url)
    unsandbox_iframes(soup)

    # Ø£Ø¶Ù Ø³ÙƒØ¨Ø±Ø¨Øª Ø¨Ø³ÙŠØ· Ù„Ø³ÙƒØ±ÙˆÙˆÙ„ Ø³Ù„Ø³ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
    tail = soup.new_tag("script")
    tail.string = """
    (function(){
      try {
        document.addEventListener("click", function(e){
          const t = e.target.closest('a[href^="#"], [data-nav]');
          if(!t) return;
          const sel = t.getAttribute("data-nav") || t.getAttribute("href");
          if(!sel || sel === "#") return;
          const el = document.querySelector(sel);
          if(!el) return console.warn("[mirror] target not found:", sel);
          e.preventDefault();
          el.scrollIntoView({behavior:"smooth", block:"start"});
        });
        console.log("[mirror] ready");
      } catch(err){ console.error("[mirror] boot failed", err); }
    })();
    """
    if soup.body:
        soup.body.append(tail)
    else:
        soup.append(tail)

    return str(soup)

# ==== UI ====
st.title("Streamlit Page Mirror")

default_url = st.query_params.get("url", [""])[0] if isinstance(st.query_params.get("url"), list) else st.query_params.get("url")
url = st.text_input("Ø¶Ø¹ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© (URL):", value=default_url or "", placeholder="https://example.com/page")

col1, col2 = st.columns(2)
with col1:
    btn_iframe = st.button("ğŸ”— Ø¬Ø±Ù‘Ø¨ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (iframe)")
with col2:
    btn_flatten = st.button("ğŸ§° Ø¹Ù…Ù„ Ù†Ø³Ø®Ø© Flatten (Ù…Ø¶Ù…Ù‘Ù†Ø©)")

st.caption("Ù†ØµÙŠØ­Ø©: Ø§Ø¨Ø¯Ø£ Ø¨Ù€ iframe. Ù„Ùˆ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙŠÙ…Ù†Ø¹ Ø§Ù„ØªØ¶Ù…ÙŠÙ†ØŒ Ø§Ø³ØªØ®Ø¯Ù… Flatten.")

if url and btn_iframe:
    # Ù„Ùˆ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙŠØ³Ù…Ø­ Ø¨Ø§Ù„ØªØ¶Ù…ÙŠÙ† â€” Ø£Ø³Ù‡Ù„ Ø·Ø±ÙŠÙ‚Ø©
    st.components.v1.iframe(url, height=900, scrolling=True)
elif url and btn_flatten:
    with st.spinner("ÙŠØ¬Ø±ÙŠ ØªØ¬Ù‡ÙŠØ² Ù†Ø³Ø®Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø¹Ø±Ø¶..."):
        try:
            flat_html = flatten(url)
            st.components.v1.html(flat_html, height=900, scrolling=True)
        except Exception as e:
            st.error(f"ØªØ¹Ø°Ù‘Ø± ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØµÙØ­Ø©: {e}")
else:
    st.info("Ø£Ø¯Ø®Ù„ Ø§Ù„Ø±Ø§Ø¨Ø· Ø«Ù… Ø§Ø®ØªØ± Ø¥Ø­Ø¯Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚ØªÙŠÙ†.")

st.markdown("---")
st.write("ğŸ’¡ ÙŠÙ…ÙƒÙ†Ùƒ ÙØªØ­ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ø¹ Ø¨Ø§Ø±Ø§Ù…ÙŠØªØ±:", 
         "`?url=https://example.com/page`")
